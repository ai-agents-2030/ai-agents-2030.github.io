<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning">
  <meta property="og:title" content="VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning"/>
  <meta property="og:description" content="VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning"/>
  <meta property="og:url" content="https://ai-agents-2030.github.io/VSC-RL/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="vision-language agent, vision-language model, reinforcement learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VSC-RL</title>
  <script type="text/javascript" async
      src="https://polyfill.io/v3/polyfill.min.js?features=es6">
  </script>
  <script type="text/javascript" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>


  <title>VSC-RL: ADVANCING AUTONOMOUS VISION-LANGUAGE AGENTS WITH VARIATIONAL SUBGOAL-CONDITIONED REINFORCEMENT LEARNING</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="font-size: 2.4rem;">VSC-RL: <br/>ADVANCING AUTONOMOUS VISION-LANGUAGE AGENTS WITH VARIATIONAL SUBGOAL-CONDITIONED REINFORCEMENT LEARNING</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Qingyuan Wu<sup>1 * †</sup>,
              </span>
              <span class="author-block">
                Jianheng Liu<sup>2 *</sup>,
              </span>
              <span class="author-block">
                Jianye Hao<sup>2 3</sup>,
              </span>
              <span class="author-block">
                Jun Wang<sup>4</sup>,
              </span>
              <span class="author-block">
                Kun Shao<sup>2 †</sup>,
              </span>
              </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> University of Liverpool<br><sup>2</sup> Huawei Noah's Ark Lab<br><sup>3</sup> Tianjin University<br>4</sup> University College London</span>
                    <span class="eql-cntrb"><small><br><sup>* </sup>Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>† </sup>Corresponding authors: qingwu2@liverpool.ac.uk, shaokun2@huawei.com</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2502.07949" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ai-agents-2030/VSC_RL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.07949" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
              <h3 class="subtitle is-5">Qualitative example of VSC-RL on the Web Shopping task: </h3>
              <div style="text-align: center">
                <img src="static/images/example_aitw.png" width="100%">
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            State-of-the-art (SOTA) reinforcement learning (RL) methods enable the vision-language agents to learn from interactions with the environment without human supervision.
            However, they struggle with learning inefficiencies in tackling real-world complex sequential decision-making tasks, especially with sparse reward signals and long-horizon dependencies. To effectively address the issue, we introduce Variational Subgoal-Conditioned RL (VSC-RL), which reformulates the vision-language sequential decision-making task as a variational goal-conditioned RL problem, allowing us to leverage advanced optimization methods to enhance learning efficiency. Specifically, VSC-RL optimizes the SubGoal Evidence Lower BOund (SGC-ELBO), which consists of (a) maximizing the subgoal-conditioned return via RL and (b) minimizing the subgoal-conditioned difference with the reference policy. We theoretically demonstrate that SGC-ELBO is equivalent to the original optimization objective, ensuring improved learning efficiency without sacrificing performance guarantees. Additionally, for real-world complex decision-making tasks, VSC-RL leverages the vision-language model to autonomously decompose the goal into feasible subgoals, enabling efficient learning. Across various benchmarks, including challenging real-world mobile device control tasks, VSC-RL significantly outperforms the SOTA vision-language agents, achieving superior performance and remarkable improvement in learning efficiency.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

 
<!-- Our Approach -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Our Approach: VSC-RL</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">         
            We propose <b>VSC-RL (Variational Subgoal-Conditioned Reinforcement Learning)</b>, 
            a novel reinforcement learning framework that enhances <b>vision-language agents</b> 
            by improving learning efficiency in complex sequential decision-making tasks. 
            We formulate the problem as a <b>variational goal-conditioned RL</b> problem 
            and introduce the <b>SubGoal-Conditioned Evidence Lower Bound (SGC-ELBO)</b> 
            as the optimization objective. 
            Our approach leverages Vision-Language Models (VLMs) to autonomously decompose 
            high-level goals into feasible subgoals, addressing challenges in 
            long-horizon tasks with sparse rewards. 
            We then optimize the agent’s policy by 
            (a) maximizing subgoal-conditioned RL returns and 
            (b) minimizing subgoal-conditioned behavior differences from a reference policy, 
            ensuring both sample efficiency and performance guarantees.

          <br>
          <br>
    
          <img src="static/images/overview.png" width="100%">
        
          <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 1rem;">
            The pipeline of VSC-RL. (a) VLM autonomously decomposes the goal \( g \) to the subgoals \( \{sg_i\}_{i=1}^N \). 
            VSC-RL optimizes the objective of SGC-ELBO consisting of (b) maximizing the subgoal-conditioned return and 
            (c) minimizing the subgoal-conditioned difference.
          </h2>

          <br>

          <p style="text-align: justify;">
            The <b>SGC-ELBO</b> is derived by decomposing the original goal-conditioned problem into smaller subgoal-conditioned tasks:</p>

          <p style="text-align: center; font-size: 1.25rem; font-family: math">SGC-ELBO(π, π<sub>ref</sub>, sg<sub>i</sub>, g) = E<sub>τ<sub>i</sub> ~ p<sub>π</sub>(τ<sub>i</sub>|sg<sub>i</sub>)</sub> [log p(O|τ<sub>i</sub>, sg<sub>i</sub>)] - KL(p<sub>π</sub>(τ<sub>i</sub>|sg<sub>i</sub>) || p<sub>π<sub>ref</sub></sub>(τ<sub>i</sub>|g))</p>

          <p style="text-align: justify;">
            where the first term maximizes the likelihood of observing outcomes \(O\) given the subgoal \(sg_i\), and the second term minimizes the Kullback-Leibler divergence (KL-divergence) between the policy \( \pi \) and the reference policy \( \pi_{\text{ref}} \), ensuring that the learned policy aligns with the reference policy while effectively solving the subgoal.</p>

          <br>
          
          <img src="static/images/example_subgoal_generator_vlm.png" width="100%">
        
          <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 1rem;">
            Autonomous vision-language subgoal generation in AitW task. The vision-language model autonomously decomposes the goal of the complicated mobile device control task into easily achievable subgoals.
          </h2>

          <p style="text-align: justify;">We employ Vision-Language Models (VLMs) to autonomously generate subgoals. Given a high-level goal \(g\), the VLM generates a set of feasible subgoals \( \{ sg_i \}_{i=1}^N \) that break down the task into simpler, achievable steps. The optimization objective for VSC-RL, using a VLM as the subgoal generator, can be written as:</p>

          <p style="text-align: center; font-size: 1.25rem; font-family: math">max<sub>&#8290;</sub> π &#8290; [&#8290; &sum;<sub>i=1</sub><sup>N</sup> &#8290; VLM(g) &#8290; [SGC-ELBO(π, π<sub>ref</sub>, sg<sub>i</sub>, g)]</sub>]</p>

          <p style="text-align: justify;">In this optimization, we maximize the sum of <b>SGC-ELBO</b> values for all generated subgoals. This process ensures that the agent not only learns to perform tasks efficiently but also generalizes across various complex decision-making problems.</p>

          <br>

          </div> 
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Our Approach -->
 

<!-- Results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Results</h2>

      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">         
            To evaluate the efficacy of <b>VSC-RL</b>, we conducted extensive experiments on challenging vision-language decision-making benchmarks, 
            particularly focusing on mobile device control tasks in the <b>AitW General</b> and <b>Web Shopping</b> datasets. Our results demonstrate that 
            VSC-RL significantly improves both <b>learning efficiency</b> and <b>task success rate</b> compared to state-of-the-art (SOTA) baselines.
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <br>
        <br>
        <br>
        <br>
        <div class="columns is-centered" style="text-align: center;">
          <div class="column is-12" style="text-align: center;">
            <img src="static/images/results-aitw.png" style="width: 70%; height: auto; object-fit: cover; margin: 0 auto;">
            <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 1rem; text-align: center; width: 70%; margin: 0 auto;">
              VSC-RL significantly outperforms all baselines in both the AitW General and Web Shopping tasks, achieving a final success rate of 0.75 in the General task and 0.6 in the Web Shopping task, surpassing the best baseline DigiRL by 15% and 20% seperately.
            </h2>
          </div>
        </div>

      </div>      
      <br>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <table id="results-table" border="1" cellpadding="5" cellspacing="0" style="width:100%; border-collapse:collapse;">
              <thead>
                <tr>
                    <th rowspan="2" style="padding:5px;">Task</th>
                    <th rowspan="2" style="padding:5px;">Task Split</th>
                    <th colspan="1" style="padding:5px;">Set-of-Marks</th>
                    <th colspan="1" style="padding:5px;">AppAgent</th>
                    <th colspan="1" style="padding:5px;">CogAgent</th>
                    <th colspan="1" style="padding:5px;">AutoUI</th>
                    <th colspan="1" style="padding:5px;">Filtered BC</th>
                    <th colspan="1" style="padding:5px;">DigiRL</th>
                    <th colspan="1" style="padding:5px;">VSC-RL (ours)</th>
                </tr>
 
            </thead>
            <tbody>
                <tr>
                    <td rowspan="2" style="padding:5px; vertical-align: middle;">General</td>
                    <td style="padding:5px;text-align: middle">Train</td>
                    <td style="padding:5px;">32.3%</td>
                    <td style="padding:5px;">14.6%</td>
                    <td style="padding:5px;">25.0%</td>
                    <td style="padding:5px;">12.5%</td>
                    <td style="padding:5px;">53.9%</td>
                    <td style="padding:5px;">64.9%</td>
                    <td style="padding:5px;"><b>73.9%</b></td>
                </tr>
                <tr>
                  <td style="padding:5px;text-align: middle">Test</td>
                  <td style="padding:5px;">16.7%</td>
                  <td style="padding:5px;">16.7%</td>
                  <td style="padding:5px;">25.0%</td>
                  <td style="padding:5px;">14.6%</td>
                  <td style="padding:5px;">62.5%</td>
                  <td style="padding:5px;">67.7%</td>
                  <td style="padding:5px;"><b>72.9%</b></td>
                </tr>
                <tr>
                    <td rowspan="4" style="padding:5px;vertical-align: middle">Web Shopping</td>
                    <td style="padding:5px;text-align: middle">Train</td>
                    <td style="padding:5px;">6.3%</td>
                    <td style="padding:5px;">5.2%</td>
                    <td style="padding:5px;">31.3%</td>
                    <td style="padding:5px;">14.6%</td>
                    <td style="padding:5px;">53.6%</td>
                    <td style="padding:5px;">55.3%</td>
                    <td style="padding:5px;"><b>64.0%</b></td>
                </tr>
                <tr>
                  <td style="padding:5px;text-align: middle">Test</td>
                  <td style="padding:5px;">11.5%</td>
                  <td style="padding:5px;">8.3%</td>
                  <td style="padding:5px;">38.5%</td>
                  <td style="padding:5px;">17.7%</td>
                  <td style="padding:5px;">54.2%</td>
                  <td style="padding:5px;">41.3%</td>
                  <td style="padding:5px;"><b>59.0%</b></td>
                </tr>
            </tbody>
          </table>
          <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 1rem;">
            The evaluated performance on the train and test datasets of the General and Web Shopping tasks. The best performance is in bold.
          </h2>

          <br>

          <div class="content">
            <h3 class="subtitle is-6" style="margin-top: 1rem;">For full results and more details, please refer to our <a href="https://arxiv_link" target="_blank" style="color:#3273dc;">paper</a>.</h3>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>
<!--End Results -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@article{wu2025vsc,
  title={VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning},
  author={Wu, Qingyuan and Liu, Jianheng and Hao, Jianye and Wang, Jun and Shao, Kun},
  journal={arXiv preprint arXiv:2502.07949},
  year={2025}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>

<style>
  #results-table {
    width: 100%;
    border-collapse: collapse;
    border-top: 2px solid black; /* 加粗顶部横线 */
    border-bottom: 2px solid black; /* 加粗底部横线 */
  }
  
  /* 去掉最左和最右列的竖线 */
  #results-table th, 
  #results-table td {
    padding: 5px;
    text-align: center;
    border-left: none;
    border-right: none;
  }
  
  #results-table > thead > tr > th,
  #results-table > tbody > tr > td {
    padding: 0.5rem;
    border: none; /* 确保没有竖线 */
  }
  
  /* 第一行顶部加粗横线 */
  #results-table tbody tr:first-child td {
    border-top: 1px solid black;
  }
  
  /* 在第三行加横线 */
  #results-table tbody tr:nth-child(3) td {
    border-top: 1px solid black; /* 第三行顶部加横线 */
  }
  
  /* 在移动端添加横向滚动条 */
  @media screen and (max-width: 768px) {
    #results-table {
      font-size: 0.75rem; /* 减小字体大小 */
    }
  
    #results-table > thead > tr > th,
    #results-table > tbody > tr > td {
      padding: 0.2rem; /* 减小内边距 */
    }
  
    /* 创建横向滚动条 */
    .table-container {
      width: 100%;
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
    }
  
    .column > .content > div > video {
      width: 100%;
    }
  }  
</style>
